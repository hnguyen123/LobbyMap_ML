{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoath\\Git\\LobbyMap_ML\\env_python10\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# # Download the WordNet corpus\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 10604/14000 [00:09<00:03, 1072.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of text_data: 557275\n",
      "First 5 entries in text_data: ['  1', 'COMMENTS OF THE CLASS OF ’85 REGULATORY RESPONSE GROUP', 'ON THE', 'PROPOSED STANDARDS OF PERFORMANCE FOR NEW, RECONSTRUCTED, AND', 'MODIFIED SOURCES AND EMISSIONS GUIDELINES FOR EXISTING SOURCES:']\n",
      "First 5 entries in years: [2022, 2022, 2022, 2022, 2022]\n",
      "First 5 entries in sectors: ['Electric Utilities', 'Electric Utilities', 'Electric Utilities', 'Electric Utilities', 'Electric Utilities']\n",
      "First 5 entries in regions: ['North America', 'North America', 'North America', 'North America', 'North America']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm  # Progress bar for monitoring\n",
    "\n",
    "# Define your evidence query\n",
    "evidence_query = \"GHG Emission Regulation\"\n",
    "\n",
    "# Define the year range to filter\n",
    "start_year = 2013\n",
    "end_year = 2023\n",
    "\n",
    "# File paths\n",
    "jsonl_file_path = r'C:\\Users\\hoath\\Git\\LobbyMap_ML\\data\\processed\\combined.jsonl'\n",
    "csv_file_path = r'C:\\Users\\hoath\\Git\\LobbyMap_ML\\data\\processed\\company_sector_region.csv'\n",
    "\n",
    "# Load the company sector and region data\n",
    "company_info = pd.read_csv(csv_file_path)\n",
    "company_info_dict = company_info.set_index('company_name').to_dict(orient='index')\n",
    "\n",
    "# Initialize lists to collect text data, years, sectors, and regions\n",
    "text_data = []\n",
    "years = []\n",
    "sectors = []\n",
    "regions = []\n",
    "\n",
    "# Read the JSONL file and extract necessary fields with a progress bar\n",
    "with open(jsonl_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in tqdm(file, total=14000):  # Update total based on actual size\n",
    "        entry = json.loads(line)\n",
    "        document_id = entry.get('document_id')\n",
    "        sentences = entry.get('sentences', [])\n",
    "        meta_evidences = entry.get('meta', {}).get('evidences', [])\n",
    "\n",
    "        for evidence in meta_evidences:\n",
    "            if isinstance(evidence, list):\n",
    "                for sub_evidence in evidence:\n",
    "                    company_name = sub_evidence.get('company_name')\n",
    "                    evidence_year = sub_evidence.get('evidence_year')\n",
    "                    evidence_query_field = sub_evidence.get('evidence_query')\n",
    "\n",
    "                    # Filter by the target evidence query and year range\n",
    "                    if evidence_query_field == evidence_query and start_year <= evidence_year <= end_year:\n",
    "                        for sentence in sentences:\n",
    "                            text = sentence['text']\n",
    "                            if isinstance(text, str) and text.strip():\n",
    "                                text_data.append(text)\n",
    "                                years.append(evidence_year)\n",
    "\n",
    "                                if company_name in company_info_dict:\n",
    "                                    sector = company_info_dict[company_name]['sector']\n",
    "                                    region = company_info_dict[company_name]['region']\n",
    "                                else:\n",
    "                                    sector = \"Unknown\"\n",
    "                                    region = \"Unknown\"\n",
    "\n",
    "                                sectors.append(sector)\n",
    "                                regions.append(region)\n",
    "            elif isinstance(evidence, dict):\n",
    "                company_name = evidence.get('company_name')\n",
    "                evidence_year = evidence.get('evidence_year')\n",
    "                evidence_query_field = evidence.get('evidence_query')\n",
    "\n",
    "                # Filter by the target evidence query and year range\n",
    "                if evidence_query_field == evidence_query and start_year <= evidence_year <= end_year:\n",
    "                    for sentence in sentences:\n",
    "                        text = sentence['text']\n",
    "                        if isinstance(text, str) and text.strip():\n",
    "                            text_data.append(text)\n",
    "                            years.append(evidence_year)\n",
    "\n",
    "                            if company_name in company_info_dict:\n",
    "                                sector = company_info_dict[company_name]['sector']\n",
    "                                region = company_info_dict[company_name]['region']\n",
    "                            else:\n",
    "                                sector = \"Unknown\"\n",
    "                                region = \"Unknown\"\n",
    "\n",
    "                            sectors.append(sector)\n",
    "                            regions.append(region)\n",
    "\n",
    "# Ensure all elements are strings and remove any that are not\n",
    "text_data = [str(text) for text in text_data if isinstance(text, str) and text.strip()]\n",
    "\n",
    "# Check if all lists have the same length\n",
    "assert len(text_data) == len(years) == len(sectors) == len(regions), \"Mismatch between text data, years, sectors, and regions\"\n",
    "\n",
    "# Print the dimensions and first 5 entries of text_data for debugging\n",
    "print(f\"Dimensions of text_data: {len(text_data)}\")\n",
    "print(\"First 5 entries in text_data:\", text_data[:5])\n",
    "print(\"First 5 entries in years:\", years[:5])\n",
    "print(\"First 5 entries in sectors:\", sectors[:5])\n",
    "print(\"First 5 entries in regions:\", regions[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique years in the dataset: [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
      "Unique sectors in the dataset: ['Airlines', 'Automobiles', 'Chemicals', 'Consumer Goods & Services', 'Diversified Mining', 'Electric Utilities', 'Oil & Gas', 'Oil & Gas Distribution', 'Other transportation', 'Steel', 'Unknown', 'cement', 'other industrials', 'paper', 'shipping']\n",
      "Unique years in the dataset: ['Africa', 'Asia', 'Australasia', 'Europe', 'Middle East', 'North America', 'South America', 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "# Check the unique years/sectors/regions in the dataset\n",
    "unique_years = sorted(set(years))\n",
    "print(f\"Unique years in the dataset: {unique_years}\")\n",
    "\n",
    "unique_sector = sorted(set(sectors))\n",
    "print(f\"Unique sectors in the dataset: {unique_sector}\")\n",
    "\n",
    "unique_region = sorted(set(regions))\n",
    "print(f\"Unique years in the dataset: {unique_region}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Normalize text (remove accents)\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove underscores, commas, and replace multiple spaces with a single space\n",
    "    text = re.sub(r'[_,]+', ' ', text)  # Replace underscores and multiple commas with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "\n",
    "    # Remove numerical tokens\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "\n",
    "    # Remove any remaining special characters, including punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove all characters except words and spaces\n",
    "\n",
    "    # Remove specific domain-related stopwords\n",
    "    domain_stopwords = set([\"reg\", \"fig\", \"data\", \"figure\", \"page\", \"additional\"])\n",
    "    text = ' '.join([word for word in text.split() if word not in domain_stopwords])\n",
    "\n",
    "    # Lemmatize each word in the text\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "    # Remove short words (less than 3 characters) and strip extra spaces\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 2])\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to each entry in text_data\n",
    "text_data = [preprocess_text(doc) for doc in text_data]\n",
    "\n",
    "# Remove any entries that are empty or consist only of whitespace after preprocessing\n",
    "text_data = [doc for doc in text_data if doc.strip()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of text_data: 478196\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimensions of text_data: {len(text_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader length: 29888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 29888/29888 [1:17:40<00:00,  6.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Define a custom dataset class for SentenceTransformer\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Explicitly set the device to CPU\n",
    "device = \"cpu\"\n",
    "\n",
    "# Create a DataLoader for batch processing\n",
    "batch_size = 16  # Reduce batch size to avoid memory issues\n",
    "num_workers = 0  # Number of CPU cores to use for data loading\n",
    "\n",
    "\n",
    "dataset = TextDataset(text_data)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Debugging: Ensure that DataLoader is working properly\n",
    "print(\"DataLoader length:\", len(dataloader))\n",
    "\n",
    "# Generate embeddings in batches with a progress bar\n",
    "embeddings = []\n",
    "for batch in tqdm(dataloader, desc=\"Generating Embeddings\", unit=\"batch\"):\n",
    "    # Ensure batch is processed on the CPU\n",
    "    batch_embeddings = embedding_model.encode(batch, convert_to_tensor=True, device=device)\n",
    "    embeddings.append(batch_embeddings)\n",
    "\n",
    "    # Debugging: Print after each batch to ensure loop is running\n",
    "    #print(f\"Processed batch size: {len(batch_embeddings)}\")\n",
    "\n",
    "# Concatenate all the embeddings into one tensor\n",
    "embeddings = torch.cat(embeddings, dim=0)\n",
    "\n",
    "# Convert back to NumPy array if needed\n",
    "embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "# Step 2: Save the embeddings to a .npy file\n",
    "np.save(r'C:\\Users\\hoath\\Git\\LobbyMap_ML\\Embeddings\\embeddings_GHG_full.npy', embeddings)\n",
    "print(\"Embeddings saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (478196, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the embeddings\n",
    "embeddings = np.load(r'C:\\Users\\hoath\\Git\\LobbyMap_ML\\Embeddings\\embeddings_GHG_full.npy')\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(\"Shape of embeddings:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# # Step 2: Save the embeddings to a .npy file\n",
    "# np.save('C:\\Users\\hoath\\Git\\LobbyMap_ML\\Embeddings\\embeddings_GHG.npy', embeddings)\n",
    "# print(\"Embeddings saved successfully.\")\n",
    "\n",
    "# # Step 3: Load the embeddings when needed\n",
    "# loaded_embeddings = np.load('C:\\Users\\hoath\\Git\\LobbyMap_ML\\Embeddings\\embeddings_GHG.npy')\n",
    "# print(f\"Loaded embeddings shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 17:03:34,747 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Topic   Count                                               Name  \\\n",
      "0      -1  196966    -1_hydrocarbon_sectoral_economywide_enforceable   \n",
      "1       0    3282  0_emissionsintensive_emissionsintensity_emissi...   \n",
      "2       1    2981  1_methanevoc_methaneemitting_methanecra_methan...   \n",
      "3       2    2735      2_epag_epadesignated_epaadministered_approves   \n",
      "4       3    2501                   3_bmwgroup_bmws_bmwblog_munichde   \n",
      "5       4    2201                     4_airlinei_boeing_flight_gojet   \n",
      "6       5    1773                   5_gaslog_gasbydesign_barnett_bpu   \n",
      "7       6    1754   6_regulacion_regulados_operaciones_disposiciones   \n",
      "8       7    1414                        7_der_deutschland_ein_neuen   \n",
      "9       8    1339        8_energetiques_ressources_etre_biodiversite   \n",
      "10      9    1199       9_charger_chargepoint_chargepoints_chargenow   \n",
      "11     10    1029                      10_ngcc_ngccs_ngcts_ngcchours   \n",
      "12     11    1026   11_recycling_recycled_wastetoenergy_recyclington   \n",
      "13     12     940     12_steelmaking_steelmaker_steelworks_steel2014   \n",
      "14     13     914     13_refinery_refiner_dieselmaking_dieselisation   \n",
      "15     14     854  14_carbonisation_carbong_carbonrelated_carbonredu   \n",
      "16     15     767                         15_fed_fedex_fedexs_fedreg   \n",
      "17     16     747  16_nuclearis_nuclearenergyindustryinnovationst...   \n",
      "18     17     737                   17_heatrate_heatwave_reheat_temp   \n",
      "19     18     726  18_waterresilient_waterborne_waterrelated_fres...   \n",
      "\n",
      "                                       Representation  \\\n",
      "0   [hydrocarbon, sectoral, economywide, enforceab...   \n",
      "1   [emissionsintensive, emissionsintensity, emiss...   \n",
      "2   [methanevoc, methaneemitting, methanecra, meth...   \n",
      "3   [epag, epadesignated, epaadministered, approve...   \n",
      "4   [bmwgroup, bmws, bmwblog, munichde, munich, de...   \n",
      "5   [airlinei, boeing, flight, gojet, netjets, air...   \n",
      "6   [gaslog, gasbydesign, barnett, bpu, watersteam...   \n",
      "7   [regulacion, regulados, operaciones, disposici...   \n",
      "8   [der, deutschland, ein, neuen, europa, antwerp...   \n",
      "9   [energetiques, ressources, etre, biodiversite,...   \n",
      "10  [charger, chargepoint, chargepoints, chargenow...   \n",
      "11  [ngcc, ngccs, ngcts, ngcchours, gasbased, gser...   \n",
      "12  [recycling, recycled, wastetoenergy, recycling...   \n",
      "13  [steelmaking, steelmaker, steelworks, steel201...   \n",
      "14  [refinery, refiner, dieselmaking, dieselisatio...   \n",
      "15  [carbonisation, carbong, carbonrelated, carbon...   \n",
      "16  [fed, fedex, fedexs, fedreg, pursuant, accorda...   \n",
      "17  [nuclearis, nuclearenergyindustryinnovationsth...   \n",
      "18  [heatrate, heatwave, reheat, temp, superheat, ...   \n",
      "19  [waterresilient, waterborne, waterrelated, fre...   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [detailed our environmental management plan th...  \n",
      "1   [future emission are function load projection ...  \n",
      "2   [proposal for legislative act reduce methane e...  \n",
      "3   [change for epa make the final federal plan an...  \n",
      "4   [the rest the group will focus only elect mobi...  \n",
      "5   [the company had discussion with boeing regard...  \n",
      "6   [water our gas business for the construction a...  \n",
      "7   [articulo los tanques deberan contar con una c...  \n",
      "8   [und davon ist derzeit auszugehen ein gesetzes...  \n",
      "9   [nous avon uvre diligence suivantes conduisant...  \n",
      "10  [this program design building the business cas...  \n",
      "11  [therefore request that epa remove from the bs...  \n",
      "12  [august the waste from our own operation will ...  \n",
      "13  [since the global steel industry one the large...  \n",
      "14  [then you have the value which further investm...  \n",
      "15  [consistent with the high fuel cost scenario a...  \n",
      "16  [fedex committed finding planetconscious solut...  \n",
      "17  [preserve the existing nuclear fleet because t...  \n",
      "18  [practice been work maintain and reduce heat r...  \n",
      "19  [freshwater the main source drinking water aro...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import MaximalMarginalRelevance, KeyBERTInspired\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from stopwordsiso import stopwords  # Import stopwords-iso\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the precomputed embeddings\n",
    "embeddings = np.load(r'C:\\Users\\hoath\\Git\\LobbyMap_ML\\Embeddings\\embeddings_GHG_full.npy')\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Define UMAP and HDBSCAN models for dimensionality reduction and clustering\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=30, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Define the ClassTfidfTransformer with both recommended parameters\n",
    "ctfidf_model = ClassTfidfTransformer(bm25_weighting=True, reduce_frequent_words=True)\n",
    "\n",
    "# Define the Maximal Marginal Relevance (MMR) model for topic representation\n",
    "mmr_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "# Define the KeyBERTInspired model for further refinement\n",
    "keybert_model = KeyBERTInspired()\n",
    "\n",
    "# Chain the MMR and KeyBERTInspired models together\n",
    "representation_model = [mmr_model, keybert_model]\n",
    "\n",
    "# Initialize BERTopic model with UMAP, HDBSCAN, customized ClassTfidfTransformer, and combined representation models\n",
    "topic_model = BERTopic(umap_model=umap_model,\n",
    "                       hdbscan_model=hdbscan_model,\n",
    "                       embedding_model=embedding_model,\n",
    "                       ctfidf_model=ctfidf_model,\n",
    "                       representation_model=representation_model)\n",
    "\n",
    "# Ensure text_data is a list of strings\n",
    "if not isinstance(text_data, list):\n",
    "    text_data = list(text_data)\n",
    "\n",
    "# Fit the BERTopic model on the precomputed embeddings and text data\n",
    "topics, probs = topic_model.fit_transform(text_data, embeddings=embeddings)\n",
    "\n",
    "# Check if representative documents are being generated\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head(20))\n",
    "\n",
    "# Save the updated topic model for future use\n",
    "# topic_model.save(r\"C:\\Users\\hoath\\Git\\LobbyMap_ML\\Models\\topic_model_GHG_4\",\n",
    "#                  serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)\n",
    "\n",
    "# Save the model with default pickle serialization\n",
    "topic_model.save(r\"C:\\Users\\hoath\\Git\\LobbyMap_ML\\Models\\topic_model_GHG_full.pkl\",\n",
    "                 save_ctfidf=True, save_embedding_model=embedding_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Topic   Count                                               Name  \\\n",
      "0      -1  196966    -1_hydrocarbon_sectoral_economywide_enforceable   \n",
      "1       0    3282  0_emissionsintensive_emissionsintensity_emissi...   \n",
      "2       1    2981  1_methanevoc_methaneemitting_methanecra_methan...   \n",
      "3       2    2735      2_epag_epadesignated_epaadministered_approves   \n",
      "4       3    2501                   3_bmwgroup_bmws_bmwblog_munichde   \n",
      "5       4    2201                     4_airlinei_boeing_flight_gojet   \n",
      "6       5    1773                   5_gaslog_gasbydesign_barnett_bpu   \n",
      "7       6    1754   6_regulacion_regulados_operaciones_disposiciones   \n",
      "8       7    1414                        7_der_deutschland_ein_neuen   \n",
      "9       8    1339        8_energetiques_ressources_etre_biodiversite   \n",
      "10      9    1199       9_charger_chargepoint_chargepoints_chargenow   \n",
      "11     10    1029                      10_ngcc_ngccs_ngcts_ngcchours   \n",
      "12     11    1026   11_recycling_recycled_wastetoenergy_recyclington   \n",
      "13     12     940     12_steelmaking_steelmaker_steelworks_steel2014   \n",
      "14     13     914     13_refinery_refiner_dieselmaking_dieselisation   \n",
      "15     14     854  14_carbonisation_carbong_carbonrelated_carbonredu   \n",
      "16     15     767                         15_fed_fedex_fedexs_fedreg   \n",
      "17     16     747  16_nuclearis_nuclearenergyindustryinnovationst...   \n",
      "18     17     737                   17_heatrate_heatwave_reheat_temp   \n",
      "19     18     726  18_waterresilient_waterborne_waterrelated_fres...   \n",
      "\n",
      "                                       Representation  \\\n",
      "0   [hydrocarbon, sectoral, economywide, enforceab...   \n",
      "1   [emissionsintensive, emissionsintensity, emiss...   \n",
      "2   [methanevoc, methaneemitting, methanecra, meth...   \n",
      "3   [epag, epadesignated, epaadministered, approve...   \n",
      "4   [bmwgroup, bmws, bmwblog, munichde, munich, de...   \n",
      "5   [airlinei, boeing, flight, gojet, netjets, air...   \n",
      "6   [gaslog, gasbydesign, barnett, bpu, watersteam...   \n",
      "7   [regulacion, regulados, operaciones, disposici...   \n",
      "8   [der, deutschland, ein, neuen, europa, antwerp...   \n",
      "9   [energetiques, ressources, etre, biodiversite,...   \n",
      "10  [charger, chargepoint, chargepoints, chargenow...   \n",
      "11  [ngcc, ngccs, ngcts, ngcchours, gasbased, gser...   \n",
      "12  [recycling, recycled, wastetoenergy, recycling...   \n",
      "13  [steelmaking, steelmaker, steelworks, steel201...   \n",
      "14  [refinery, refiner, dieselmaking, dieselisatio...   \n",
      "15  [carbonisation, carbong, carbonrelated, carbon...   \n",
      "16  [fed, fedex, fedexs, fedreg, pursuant, accorda...   \n",
      "17  [nuclearis, nuclearenergyindustryinnovationsth...   \n",
      "18  [heatrate, heatwave, reheat, temp, superheat, ...   \n",
      "19  [waterresilient, waterborne, waterrelated, fre...   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [detailed our environmental management plan th...  \n",
      "1   [future emission are function load projection ...  \n",
      "2   [proposal for legislative act reduce methane e...  \n",
      "3   [change for epa make the final federal plan an...  \n",
      "4   [the rest the group will focus only elect mobi...  \n",
      "5   [the company had discussion with boeing regard...  \n",
      "6   [water our gas business for the construction a...  \n",
      "7   [articulo los tanques deberan contar con una c...  \n",
      "8   [und davon ist derzeit auszugehen ein gesetzes...  \n",
      "9   [nous avon uvre diligence suivantes conduisant...  \n",
      "10  [this program design building the business cas...  \n",
      "11  [therefore request that epa remove from the bs...  \n",
      "12  [august the waste from our own operation will ...  \n",
      "13  [since the global steel industry one the large...  \n",
      "14  [then you have the value which further investm...  \n",
      "15  [consistent with the high fuel cost scenario a...  \n",
      "16  [fedex committed finding planetconscious solut...  \n",
      "17  [preserve the existing nuclear fleet because t...  \n",
      "18  [practice been work maintain and reduce heat r...  \n",
      "19  [freshwater the main source drinking water aro...  \n"
     ]
    }
   ],
   "source": [
    "# To fine-tune further here XXXX\n",
    "\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import MaximalMarginalRelevance, KeyBERTInspired\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from stopwordsiso import stopwords  # Import stopwords-iso\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the topic model\n",
    "# Load the model\n",
    "topic_model = BERTopic.load(r\"C:\\Users\\hoath\\Git\\LobbyMap_ML\\Models\\topic_model_GHG_full.pkl\",\n",
    "                            embedding_model=embedding_model)\n",
    "\n",
    "# Check if representative documents are being generated\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head(20))\n",
    "\n",
    "# Define languages for which you want to include stopwords (those with at least 10 documents in column 2)\n",
    "languages = [\n",
    "    'af', 'ca', 'cy', 'da', 'de', 'en', 'et', 'es', 'fi', 'fr', 'hr', \n",
    "    'hu', 'id', 'it', 'nl', 'no', 'ro', 'pt', 'pl', 'tl', 'vi', 'sv', \n",
    "    'sl', 'so', 'sw', 'sq', 'lt', 'tr', 'sk'\n",
    "]\n",
    "\n",
    "# Create a combined stopwords list from the selected languages\n",
    "multilingual_stopwords = set()\n",
    "for lang in languages:\n",
    "    multilingual_stopwords.update(stopwords(lang))\n",
    "\n",
    "# Define additional stopwords based on your analysis\n",
    "additional_stopwords = {\n",
    "    \"14\", \"50\", \"70\", \"142\", \"report\", \"combined\", \"statements\", \"corporate\", \n",
    "    \"financial\", \"results\", \"services\", \"emissions\", \"climate\", \"action\", \n",
    "    \"agreement\", \"protection\", \"____\", \" \", \"\",  \n",
    "    \"activities\",  \"individual\", \"units\", \"source\", \"vehicle\", \n",
    "    \"22\", \"23\", \"26\", \"2022\", \"30\", \"40\", \"25\", \"33\", \"12\", \"13\", \"15\", \"U.S.C.\", \n",
    "    \"Reg.\", \"_\", \"__\", \"page\", \"additional\", \"dow\", \"edf\", \"developpement\", \"bmw\"\n",
    "}\n",
    "\n",
    "# Add the additional stopwords to the multilingual stopwords set\n",
    "multilingual_stopwords.update(additional_stopwords)\n",
    "\n",
    "# Convert multilingual_stopwords set back to a list for use in CountVectorizer\n",
    "multilingual_stopwords = list(multilingual_stopwords)\n",
    "\n",
    "# Fine-tune topic representations with a custom vectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words=multilingual_stopwords, ngram_range=(1, 3), min_df=20)\n",
    "topic_model.update_topics(text_data, vectorizer_model=vectorizer_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Topic   Count                                               Name  \\\n",
      "0      -1  196966                 -1_fuel_electricity_coal_renewable   \n",
      "1       0    3282  0_emission rate_emission reduction_reduction e...   \n",
      "2       1    2981          1_methane_methane emission_detection_leak   \n",
      "3       2    2735            2_epa epa_epa_federal plan_epa proposes   \n",
      "4       3    2501                       3_bmw_mini_series_automotive   \n",
      "5       4    2201                 4_airport_airline_carrier_aircraft   \n",
      "6       5    1773          5_natural gas_pipeline_natural_gas supply   \n",
      "7       6    1754                      6_integral_mexico_base_sector   \n",
      "8       7    1414                           7_fur_basf_euro_deutsche   \n",
      "9       8    1339                      8_engie_durable_salary_client   \n",
      "10      9    1199              9_charging_charge_infrastructure_fast   \n",
      "11     10    1029     10_capacity factor_redispatch_utilization_unit   \n",
      "12     11    1026                11_waste_recycling_recycled_plastic   \n",
      "13     12     940                        12_steel_zealand_iron_scrap   \n",
      "14     13     914              13_refinery_refining_closure_importer   \n",
      "15     14     854      14_carbon pricing_carbon price_pricing_carbon   \n",
      "16     15     767                     15_fed_citing_submits_pursuant   \n",
      "17     16     747  16_nuclear_nuclear plant_nuclear power_retirement   \n",
      "18     17     737                 17_heat rate_heat_rate_improvement   \n",
      "19     18     726                18_water_fresh_withdrawal_discharge   \n",
      "\n",
      "                                       Representation  \\\n",
      "0   [fuel, electricity, coal, renewable, cost, ene...   \n",
      "1   [emission rate, emission reduction, reduction ...   \n",
      "2   [methane, methane emission, detection, leak, o...   \n",
      "3   [epa epa, epa, federal plan, epa proposes, rul...   \n",
      "4   [bmw, mini, series, automotive, worldwide, boa...   \n",
      "5   [airport, airline, carrier, aircraft, flight, ...   \n",
      "6   [natural gas, pipeline, natural, gas supply, g...   \n",
      "7   [integral, mexico, base, sector, interior, per...   \n",
      "8   [fur, basf, euro, deutsche, bayer, fast, kilom...   \n",
      "9   [engie, durable, salary, client, france, evolu...   \n",
      "10  [charging, charge, infrastructure, fast, stati...   \n",
      "11  [capacity factor, redispatch, utilization, uni...   \n",
      "12  [waste, recycling, recycled, plastic, landfill...   \n",
      "13  [steel, zealand, iron, scrap, strength, posco,...   \n",
      "14  [refinery, refining, closure, importer, crude,...   \n",
      "15  [carbon pricing, carbon price, pricing, carbon...   \n",
      "16  [fed, citing, submits, pursuant, quoting, jan,...   \n",
      "17  [nuclear, nuclear plant, nuclear power, retire...   \n",
      "18  [heat rate, heat, rate, improvement, variabili...   \n",
      "19  [water, fresh, withdrawal, discharge, quality ...   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [detailed our environmental management plan th...  \n",
      "1   [future emission are function load projection ...  \n",
      "2   [proposal for legislative act reduce methane e...  \n",
      "3   [change for epa make the final federal plan an...  \n",
      "4   [the rest the group will focus only elect mobi...  \n",
      "5   [the company had discussion with boeing regard...  \n",
      "6   [water our gas business for the construction a...  \n",
      "7   [articulo los tanques deberan contar con una c...  \n",
      "8   [und davon ist derzeit auszugehen ein gesetzes...  \n",
      "9   [nous avon uvre diligence suivantes conduisant...  \n",
      "10  [this program design building the business cas...  \n",
      "11  [therefore request that epa remove from the bs...  \n",
      "12  [august the waste from our own operation will ...  \n",
      "13  [since the global steel industry one the large...  \n",
      "14  [then you have the value which further investm...  \n",
      "15  [consistent with the high fuel cost scenario a...  \n",
      "16  [fedex committed finding planetconscious solut...  \n",
      "17  [preserve the existing nuclear fleet because t...  \n",
      "18  [practice been work maintain and reduce heat r...  \n",
      "19  [freshwater the main source drinking water aro...  \n"
     ]
    }
   ],
   "source": [
    "# Check if representative documents are being generated\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
